{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.x"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Recovered Notebook\n",
        "The original file was not valid JSON. Its raw contents are included below for reference.\n\n",
        "```\n",
        "{\n \"cells\": [\n  {\n   \"cell_type\": \"markdown\",\n   \"id\": \"7fb27b941602401d91542211134fc71a\",\n   \"metadata\": {},\n   \"source\": [\n    \"# Read Edge AI Data (All Formats)\\n\",\n    \"*Generated 2025-08-19T04:24:17.353547+00:00*\\n\\n\",\n    \"This notebook demonstrates how to read **JSONL**, **Parquet**, **Avro**, and **Protobuf** records from this repository.\\n\",\n    \"\\n\",\n    \"## Setup\\n\",\n    \"Install dependencies (if needed) and set base paths.\"\n   ]\n  },\n  {\n   \"cell_type\": \"code\",\n   \"execution_count\": null,\n   \"id\": \"acae54e37e7d407bbb7b55eff062a284\",\n   \"metadata\": {},\n   \"outputs\": [],\n   \"source\": [\n    \"import json\\n\",\n    \"import sys\\n\",\n    \"from pathlib import Path\\n\",\n    \"import pandas as pd\\n\",\n    \"\\n\",\n    \"BASE = Path('..').resolve().parent if (Path.cwd().name == 'notebooks') else Path('.').resolve()\\n\",\n    \"DATA = BASE / 'data' / 'samples'\\n\",\n    \"SCHEMA = BASE / 'schema'\\n\",\n    \"PROTO = BASE / 'proto'\\n\",\n    \"print('BASE:', BASE)\\n\",\n    \"print('DATA:', DATA)\\n\",\n    \"print('SCHEMA:', SCHEMA)\\n\",\n    \"print('PROTO:', PROTO)\"\n   ]\n  },\n  {\n   \"cell_type\": \"markdown\",\n   \"id\": \"9a63283cbaf04dbcab1f6479b197f3a8\",\n   \"metadata\": {},\n   \"source\": [\n    \"## JSONL (hot logs)\"\n   ]\n  },\n  {\n   \"cell_type\": \"code\",\n   \"execution_count\": null,\n   \"id\": \"8dd0d8092fe74a7c96281538738b07e2\",\n   \"metadata\": {},\n   \"outputs\": [],\n   \"source\": [\n    \"jsonl_files = sorted((DATA / 'hot' / 'temperature').rglob('*.jsonl'))\\n\",\n    \"jsonl_files[:3]\"\n   ]\n  },\n  {\n   \"cell_type\": \"code\",\n   \"execution_count\": null,\n   \"id\": \"72eea5119410473aa328ad9291626812\",\n   \"metadata\": {},\n   \"outputs\": [],\n   \"source\": [\n    \"rows = []\\n\",\n    \"for f in jsonl_files:\\n\",\n    \"    with open(f) as fh:\\n\",\n    \"        for line in fh:\\n\",\n    \"            line=line.strip()\\n\",\n    \"            if not line:\\n\",\n                    continue\\n\",\n    \"            rows.append(json.loads(line))\\n\",\n    \"df_jsonl = pd.DataFrame(rows)\\n\",\n    \"df_jsonl.head()\"\n   ]\n  },\n  {\n   \"cell_type\": \"markdown\",\n   \"id\": \"8edb47106e1a46a883d545849b8ab81b\",\n   \"metadata\": {},\n   \"source\": [\n    \"## Parquet (batch analytics)\"\n   ]\n  },\n  {\n   \"cell_type\": \"code\",\n   \"execution_count\": null,\n   \"id\": \"10185d26023b46108eb7d9f57d49d2b3\",\n   \"metadata\": {},\n   \"outputs\": [],\n   \"source\": [\n    \"# We try pyarrow first; if not available use fastparquet\\n\",\n    \"pq_files = sorted((DATA / 'batch').rglob('*.parquet'))\\n\",\n    \"pq_files[:3]\"\n   ]\n  },\n  {\n   \"cell_type\": \"code\",\n   \"execution_count\": null,\n   \"id\": \"8763a12b2bbd4a93a75aff182afb95dc\",\n   \"metadata\": {},\n   \"outputs\": [],\n   \"source\": [\n    \"df_parquet = None\\n\",\n    \"if pq_files:\\n\",\n    \"    try:\\n\",\n    \"        df_parquet = pd.read_parquet(pq_files[0])\\n\",\n    \"    except Exception as e:\\n\",\n    \"        try:\\n\",\n    \"            df_parquet = pd.read_parquet(pq_files[0], engine='fastparquet')\\n\",\n    \"        except Exception as e2:\\n\",\n    \"            print('Parquet read failed:', e, e2)\\n\",\n    \"df_parquet.head() if df_parquet is not None else 'No parquet files found (install pyarrow or fastparquet).'\\n\"\n   ]\n  },\n  {\n   \"cell_type\": \"markdown\",\n   \"id\": \"7623eae2785240b9bd12b16a66d81610\",\n   \"metadata\": {},\n   \"source\": [\n    \"## Avro (data contracts + records)\"\n   ]\n  },\n  {\n   \"cell_type\": \"code\",\n   \"execution_count\": null,\n   \"id\": \"7cdc8c89c7104fffa095e18ddfef8986\",\n   \"metadata\": {},\n   \"outputs\": [],\n   \"source\": [\n    \"from fastavro import parse_schema, writer, reader\\n\",\n    \"\\n\",\n    \"avsc = json.load(open(SCHEMA / 'temperature.avsc'))\\n\",\n    \"parsed = parse_schema(avsc)\\n\",\n    \"\\n\",\n    \"# Create a temp in-memory Avro file to demonstrate round-trip\\n\",\n    \"records = [\\n\",\n    \"    {\\\"device_id\\\":\\\"D-1\\\",\\\"site\\\":\\\"A\\\",\\\"ts\\\": 1724054400000, \\\"celsius\\\": 70.1, \\\"status\\\": None},\\n\",\n    \"    {\\\"device_id\\\":\\\"D-2\\\",\\\"site\\\":\\\"A\\\",\\\"ts\\\": 1724058000000, \\\"celsius\\\": 83.3, \\\"status\\\": \\\"ALERT\\\"}\\n\",\n    \"]\\n\",\n    \"tmp_avro = BASE / 'data' / 'samples' / 'avro-demo'\\n\",\n    \"tmp_avro.mkdir(parents=True, exist_ok=True)\\n\",\n    \"avro_path = tmp_avro / 'temperature-demo.avro'\\n\",\n    \"with open(avro_path, 'wb') as out:\\n\",\n    \"    writer(out, parsed, records)\\n\",\n    \"print('Wrote', avro_path)\\n\",\n    \"\\n\",\n    \"with open(avro_path, 'rb') as inp:\\n\",\n    \"    recs = list(reader(inp))\\n\",\n    \"pd.DataFrame(recs).head()\"\n   ]\n  },\n  {\n   \"cell_type\": \"markdown\",\n   \"id\": \"b118ea5561624da68c537baed56e602f\",\n   \"metadata\": {},\n   \"source\": [\n    \"## Protobuf (binary records)\"\n   ]\n  },\n  {\n   \"cell_type\": \"code\",\n   \"execution_count\": null,\n   \"id\": \"938c804e27f84196a10c8828c723f798\",\n   \"metadata\": {},\n   \"outputs\": [],\n   \"source\": [\n    \"import subprocess\\n\",\n    \"from pathlib import Path\\n\",\n    \"\\n\",\n    \"proto = PROTO / 'temperature.proto'\\n\",\n    \"if not proto.exists():\\n\",\n    \"    raise FileNotFoundError(proto)\\n\",\n    \"\\n\",\n    \"# Attempt to compile .proto -> Python module at runtime if protoc is available\\n\",\n    \"module_dir = BASE / 'notebooks' / '__pb__'\\n\",\n    \"module_dir.mkdir(parents=True, exist_ok=True)\\n\",\n    \"py_out = module_dir\\n\",\n    \"\\n\",\n    \"def have_protoc():\\n\",\n    \"    from shutil import which\\n\",\n    \"    return which('protoc') is not None\\n\",\n    \"\\n\",\n    \"compiled = False\\n\",\n    \"if have_protoc():\\n\",\n    \"    cmd = ['protoc', f'--proto_path={PROTO}', f'--python_out={py_out}', str(proto)]\\n\",\n    \"    r = subprocess.run(cmd, capture_output=True, text=True)\\n\",\n    \"    if r.returncode == 0:\\n\",\n    \"        compiled = True\\n\",\n    \"    else:\\n\",\n    \"        print('protoc failed:', r.stderr)\\n\",\n    \"else:\\n\",\n    \"    print('protoc not found; skipping runtime compile. You can precompile with `protoc`.')\\n\",\n    \"\\n\",\n    \"if compiled:\\n\",\n    \"    sys.path.append(str(module_dir))\\n\",\n    \"    import temperature_pb2 as pb\\n\",\n    \"    m = pb.TemperatureReading()\\n\",\n    \"    m.device_id = 'D-123'\\n\",\n            m.site='A'\\n\",\n            m.ts_ms=1724054400000\\n\",\n            m.celsius=81.2\\n\",\n            m.status='ALERT'\\n\",\n    \"    b = m.SerializeToString()\\n\",\n    \"    print('Encoded bytes len:', len(b))\\n\",\n    \"    m2 = pb.TemperatureReading()\\n\",\n    \"    m2.ParseFromString(b)\\n\",\n    \"    m2\\n\",\n    \"else:\\n\",\n    \"    'Install protoc to compile and parse protobuf messages in this notebook.'\\n\"\n   ]\n  },\n  {\n   \"cell_type\": \"markdown\",\n   \"id\": \"504fb2a444614c0babb325280ed9130a\",\n   \"metadata\": {},\n   \"source\": [\n    \"## DuckDB quick SQL on Parquet/JSON\\n\",\n    \"Optional, but handy for ad-hoc exploration.\"\n   ]\n  },\n  {\n   \"cell_type\": \"code\",\n   \"execution_count\": null,\n   \"id\": \"59bbdb311c014d738909a11f9e486628\",\n   \"metadata\": {},\n   \"outputs\": [],\n   \"source\": [\n    \"import duckdb\\n\",\n    \"con = duckdb.connect()\\n\",\n    \"con.execute(\\\"PRAGMA threads=4;\\\")\\n\",\n    \"parquet_glob = str((DATA / 'batch').resolve() / '**/*.parquet')\\n\",\n    \"jsonl_glob = str((DATA / 'hot' / 'temperature').resolve() / '**/*.jsonl')\\n\",\n    \"try:\\n\",\n    \"    print('JSONL sample:')\\n\",\n    \"    print(con.execute(f\\\"SELECT * FROM read_json_auto('{jsonl_glob}') LIMIT 5\\\").fetchdf())\\n\",\n    \"except Exception as e:\\n\",\n    \"    print('DuckDB JSONL read error:', e)\\n\",\n    \"try:\\n\",\n    \"    print('Parquet sample:')\\n\",\n    \"    print(con.execute(f\\\"SELECT * FROM read_parquet('{parquet_glob}') LIMIT 5\\\").fetchdf())\\n\",\n    \"except Exception as e:\\n\",\n    \"    print('DuckDB Parquet read error:', e)\"\n   ]\n  }\n ],\n \"metadata\": {\n  \"kernelspec\": {\n   \"display_name\": \"Python 3\",\n   \"language\": \"python\",\n   \"name\": \"python3\"\n  },\n  \"language_info\": {\n   \"name\": \"python\",\n   \"version\": \"3.x\"\n  }\n },\n \"nbformat\": 4,\n \"nbformat_minor\": 5\n}\n",
        "\n```"
      ]
    }
  ]
}
